{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3438676f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    precision_recall_curve,\n",
    "    auc,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96df90f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8_/9rv7b7fd60g0_ghqkjccmhkc0000gn/T/ipykernel_91655/3582955995.py:15: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_comp = pd.read_csv(\n",
      "/var/folders/8_/9rv7b7fd60g0_ghqkjccmhkc0000gn/T/ipykernel_91655/3582955995.py:15: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df_comp = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "# Load Monthly CRSP\n",
    "\n",
    "CRSP_PATH = 'data/monthly_crsp.csv'\n",
    "df_crsp = pd.read_csv(\n",
    "    CRSP_PATH ,\n",
    "    parse_dates=['MthCalDt'],\n",
    "    usecols=['PERMNO','CUSIP','MthCalDt','MthRet']\n",
    ")\n",
    "\n",
    "\n",
    "# Load Compustat Fundamentals\n",
    "\n",
    "COMP_PATH = 'data/CompFirmCharac.csv'\n",
    "\n",
    "df_comp = pd.read_csv(\n",
    "    COMP_PATH,\n",
    "    parse_dates=['datadate'], dayfirst=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c01ee4",
   "metadata": {},
   "source": [
    "### CLEAN CRSP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "71ecff37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1: Keep only rows where MthRet is available and cast to float\n",
    "df_crsp = df_crsp.dropna(subset=['MthRet']).copy()\n",
    "df_crsp['MthRet'] = df_crsp['MthRet'].astype(float)\n",
    "\n",
    "# 2.2: Sort by CUSIP, date so that shift is correct\n",
    "df_crsp['date'] = pd.to_datetime(df_crsp['MthCalDt'].astype(str), format='mixed')\n",
    "df_crsp = df_crsp.sort_values(['CUSIP','date']).reset_index(drop=True)\n",
    "\n",
    "# 2.3: Create next‐month return target (binary)\n",
    "df_crsp['Ret_t1'] = df_crsp.groupby('CUSIP')['MthRet'].shift(-1)\n",
    "df_crsp['y'] = (df_crsp['Ret_t1'] > 0).astype(int)\n",
    "df_crsp = df_crsp.dropna(subset=['y']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc8b4c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# 2.4: Generate price‐history features (momentum + volatility)\n",
    "#\n",
    "#   - 3M momentum: cumulative return over past 3 months (t-3 → t-1)\n",
    "#   - 6M momentum: cumulative return over past 6 months\n",
    "#   - 12M momentum: cumulative return over past 12 months\n",
    "#   - 12M rolling volatility: std of monthly returns over past 12 months\n",
    "#\n",
    "def compute_momentum_and_vol(df):\n",
    "    df = df.sort_values('date')\n",
    "    # Rolling log(1+return), because cumulative product of (1 + ret) = exp(sum(log(1+ret)))\n",
    "    df['log1p_ret'] = np.log1p(df['MthRet'])\n",
    "    df['log1p_ret_shift1'] = df.groupby('CUSIP')['log1p_ret'].shift(1)\n",
    "    df['cum12_1_log'] = df.groupby('CUSIP')['log1p_ret_shift1'].rolling(window=11).sum().reset_index(0,drop=True)\n",
    "    df['mom_12_1'] = np.expm1(df['cum12_1_log'])\n",
    "    df['cum3m_log'] = df.groupby('CUSIP')['log1p_ret'].rolling(window=3, min_periods=3).sum().reset_index(0,drop=True)\n",
    "    df['cum6m_log'] = df.groupby('CUSIP')['log1p_ret'].rolling(window=6, min_periods=6).sum().reset_index(0,drop=True)\n",
    "    df['cum12m_log'] = df.groupby('CUSIP')['log1p_ret'].rolling(window=12, min_periods=12).sum().reset_index(0,drop=True)\n",
    "    df['momentum_3m'] = np.expm1(df['cum3m_log'])    # exp(sum)-1 => (1+r1)*(1+r2)*(1+r3) - 1\n",
    "    df['momentum_6m'] = np.expm1(df['cum6m_log'])\n",
    "    df['momentum_12m'] = np.expm1(df['cum12m_log'])\n",
    "    df['volatility_12m'] = df.groupby('CUSIP')['MthRet'].rolling(window=12, min_periods=12).std().reset_index(0,drop=True)\n",
    "    # Drop intermediate log columns\n",
    "    return df.drop(columns=['log1p_ret','cum3m_log','cum6m_log','cum12m_log'])\n",
    "\n",
    "df_crsp = compute_momentum_and_vol(df_crsp)\n",
    "\n",
    "# 2.5: Trim CUSIP to 8 characters (for merging) and drop NA\n",
    "df_crsp['cusip'] = df_crsp['CUSIP'].astype(str).str[:8]\n",
    "df_crsp = df_crsp.dropna(subset=['cusip']).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a84c12",
   "metadata": {},
   "source": [
    "### CLEAN COMPFIRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acc27fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1: Keep only Industrial & Consolidated\n",
    "df_comp = df_comp[\n",
    "    (df_comp['consol'] == 'C')\n",
    "].copy()\n",
    "\n",
    "# 3.2: Trim & parse keys/dates\n",
    "df_comp['cusip'] = df_comp['cusip'].astype(str).str[:8]\n",
    "df_comp['datadate'] = pd.to_datetime(df_comp['datadate'])\n",
    "df_comp = df_comp.dropna(subset=['cusip','datadate']).copy()\n",
    "\n",
    "# 3.3: Build “effective_date” = datadate + 45 calendar days,\n",
    "#      so that we only use Q data ~45 days after quarter‐end.\n",
    "df_comp['effective_date'] = df_comp['datadate'] + pd.Timedelta(days=45)\n",
    "df_comp = df_comp.set_index('effective_date').sort_index()\n",
    "\n",
    "# 3.4: Select a larger fundamental set (YTD flows + per‐share metrics)\n",
    "fundamental_cols = [\n",
    "    'revty',    # Revenue YTD\n",
    "    'saley',    # Sales YTD\n",
    "    'capxy',    # CapEx YTD\n",
    "    'oibdpy',   # EBITDA YTD\n",
    "    'rdipay',   # R&D expense YTD\n",
    "    'xsgay',    # SG&A expense YTD\n",
    "    'txpdy',    # Tax provision YTD\n",
    "    'epsfxy',   # Diluted EPS ex‐extra YTD\n",
    "    'cshfdy',   # Diluted shares YTD (millions)\n",
    "    'xoptepsy'  # Option expense per share YTD\n",
    "]\n",
    "\n",
    "df_comp_small = df_comp[['cusip'] + fundamental_cols].copy()\n",
    "\n",
    "# 3.5: For each “cusip + quarter,” drop exact duplicates\n",
    "df_comp_small = df_comp_small.reset_index().drop_duplicates(\n",
    "    subset=['cusip','effective_date']\n",
    ").set_index('effective_date').sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031bbf43",
   "metadata": {},
   "source": [
    "### MERGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e3fc5166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1: Set df_crsp index to “date”\n",
    "df_crsp = df_crsp.set_index('date').sort_index()\n",
    "\n",
    "# 4.2: Merge (for every month, get the most recent Compustat row ≤ that month’s date)\n",
    "df_merged = pd.merge_asof(\n",
    "    left = df_crsp.reset_index(),\n",
    "    right = df_comp_small.reset_index(),\n",
    "    left_on = 'date',\n",
    "    right_on = 'effective_date',\n",
    "    by = 'cusip',\n",
    "    direction = 'backward',\n",
    "    allow_exact_matches=True\n",
    ").set_index('date')\n",
    "\n",
    "# 4.3: Drop rows where any of our fundamentals are NA, since we can’t compute ratios otherwise\n",
    "df_merged = df_merged.dropna(subset=fundamental_cols + ['y']).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "570dc693",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_merged.copy()\n",
    "\n",
    "# 5.1: Engineer simple ratios (safe‐guard divisions by zero)\n",
    "df['EBIT_margin']      = df['oibdpy'] / df['saley'].replace({0: np.nan})\n",
    "df['R&D_intensity']    = df['rdipay'] / df['saley'].replace({0: np.nan})\n",
    "df['SGA_intensity']    = df['xsgay'] / df['saley'].replace({0: np.nan})\n",
    "df['Tax_rate']         = df['txpdy']  / df['oibdpy'].replace({0: np.nan})\n",
    "df['Capex_to_Revenue'] = df['capxy']  / df['revty'].replace({0: np.nan})\n",
    "\n",
    "# 5.2: Compute QoQ growth rates on YTD fundamentals\n",
    "for col in ['revty','oibdpy','rdipay','xsgay']:\n",
    "    df[col + '_QoQ_growth'] = df.groupby('cusip')[col].pct_change()  # (This QY / Last QY) - 1\n",
    "\n",
    "# 5.3: Optionally drop some raw dollar‐amount YTD columns if you want just ratios\n",
    "#      (otherwise let the model pick scale vs. ratio)\n",
    "# df = df.drop(columns=['revty','saley','capxy','oibdpy','rdipay','xsgay','txpdy','epsfxy','cshfdy','xoptepsy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b27bfe5",
   "metadata": {},
   "source": [
    "### TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e77625e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [\n",
    "    # Price/technical:\n",
    "    'momentum_3m', 'momentum_6m', 'momentum_12m', 'volatility_12m',\n",
    "\n",
    "    # Basic YTD fundamentals (optional—tree can split on scale):\n",
    "    'revty', 'saley', 'capxy', 'oibdpy', 'rdipay', 'xsgay', 'txpdy', 'epsfxy', 'cshfdy', 'xoptepsy',\n",
    "\n",
    "    # Engineered ratios:\n",
    "    'EBIT_margin', 'R&D_intensity', 'SGA_intensity', 'Tax_rate', 'Capex_to_Revenue',\n",
    "\n",
    "    # QoQ growth rates:\n",
    "    'revty_QoQ_growth', 'oibdpy_QoQ_growth', 'rdipay_QoQ_growth', 'xsgay_QoQ_growth'\n",
    "]\n",
    "\n",
    "# Drop any rows where engineered features are NaN\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df = df.dropna(subset=feature_columns + ['y']).copy()\n",
    "\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9980d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of a fixed 80/20 cutoff, build an expanding‐window cross‐validation\n",
    "# but keep a final out‐of‐sample test set (last 20% of months).\n",
    "n_obs = len(df)\n",
    "cutpoint = int(n_obs * 0.8)\n",
    "\n",
    "X_train = X.iloc[:cutpoint]\n",
    "y_train = y.iloc[:cutpoint]\n",
    "\n",
    "X_test  = X.iloc[cutpoint:]\n",
    "y_test  = y.iloc[cutpoint:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8eddb922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best parameters: {'clf__max_depth': 7, 'clf__max_features': 'sqrt', 'clf__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler',   StandardScaler()),   # scale ratio features so splits are easier\n",
    "    ('clf',      RandomForestClassifier(random_state=42, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [100, 200],\n",
    "    'clf__max_depth': [5, 7, 9],\n",
    "    'clf__max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    cv=tscv,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "best_model = grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bcb69cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.42      0.41       355\n",
      "           1       0.61      0.61      0.61       541\n",
      "\n",
      "    accuracy                           0.53       896\n",
      "   macro avg       0.51      0.51      0.51       896\n",
      "weighted avg       0.53      0.53      0.53       896\n",
      "\n",
      "Test ROC AUC:  0.5328\n",
      "Test PR AUC:   0.6430\n",
      "Confusion Matrix (low values = better balance):\n",
      " [[148 207]\n",
      " [213 328]]\n",
      "\n",
      "Top 10 Feature Importances:\n",
      "momentum_12m         0.068899\n",
      "Capex_to_Revenue     0.056873\n",
      "momentum_6m          0.055486\n",
      "Tax_rate             0.051785\n",
      "momentum_3m          0.051582\n",
      "volatility_12m       0.049099\n",
      "oibdpy_QoQ_growth    0.049075\n",
      "xsgay_QoQ_growth     0.047390\n",
      "cshfdy               0.046634\n",
      "revty_QoQ_growth     0.044819\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 9.1: Prediction & Classification Report\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"\\nClassification Report on Test Set:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 9.2: ROC AUC + Precision‐Recall AUC\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "print(f\"Test ROC AUC:  {roc_auc:.4f}\")\n",
    "print(f\"Test PR AUC:   {pr_auc:.4f}\")\n",
    "\n",
    "# 9.3: Display a confusion matrix if you like\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix (low values = better balance):\\n\", cm)\n",
    "\n",
    "# ───────────\n",
    "# 10. FEATURE IMPORTANCE AND NEXT STEPS\n",
    "# ───────────\n",
    "\n",
    "importances = best_model.named_steps['clf'].feature_importances_\n",
    "feat_imp = pd.Series(importances, index=feature_columns).sort_values(ascending=False)\n",
    "print(\"\\nTop 10 Feature Importances:\")\n",
    "print(feat_imp.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a489edc",
   "metadata": {},
   "source": [
    "TRAINING 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654d833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [\n",
    "    # Price/technical:\n",
    "    'momentum_3m', 'momentum_6m', 'momentum_12m', 'volatility_12m',\n",
    "\n",
    "    # Basic YTD fundamentals (optional—tree can split on scale):\n",
    "    'revty', 'saley', 'capxy', 'oibdpy', 'rdipay', 'xsgay', 'txpdy', 'epsfxy', 'cshfdy', 'xoptepsy',\n",
    "\n",
    "    # Engineered ratios:\n",
    "    'EBIT_margin', 'R&D_intensity', 'SGA_intensity', 'Tax_rate', 'Capex_to_Revenue',\n",
    "\n",
    "    # QoQ growth rates:\n",
    "    'revty_QoQ_growth', 'oibdpy_QoQ_growth', 'rdipay_QoQ_growth', 'xsgay_QoQ_growth'\n",
    "]\n",
    "\n",
    "# Drop any rows where engineered features are NaN\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df = df.dropna(subset=feature_columns + ['y']).copy()\n",
    "\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8008f0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of a fixed 80/20 cutoff, build an expanding‐window cross‐validation\n",
    "# but keep a final out‐of‐sample test set (last 20% of months).\n",
    "n_obs = len(df)\n",
    "cutpoint = int(n_obs * 0.8)\n",
    "\n",
    "X_train = X.iloc[:cutpoint]\n",
    "y_train = y.iloc[:cutpoint]\n",
    "\n",
    "X_test  = X.iloc[cutpoint:]\n",
    "y_test  = y.iloc[cutpoint:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e02defc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:36:38] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:36:38] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:36:38] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:36:38] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:36:38] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:36:38] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:36:38] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:36:38] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:36:39] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:36:39] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:36:39] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:36:39] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:36:39] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:36:39] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:36:39] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:36:39] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:36:39] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:36:39] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:36:39] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:36:39] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:36:39] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:36:39] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:36:39] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [17:36:39] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 24\u001b[0m\n\u001b[1;32m     17\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf__n_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m],\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf__max_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m7\u001b[39m],\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf__learning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.05\u001b[39m]\n\u001b[1;32m     21\u001b[0m }\n\u001b[1;32m     23\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(pipe, param_grid, cv\u001b[38;5;241m=\u001b[39mTimeSeriesSplit(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m), scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXGBoost Best params:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[1;32m     26\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1020\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1571\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    967\u001b[0m         )\n\u001b[1;32m    968\u001b[0m     )\n\u001b[0;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    993\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler',   StandardScaler()),  \n",
    "    ('clf',      XGBClassifier(\n",
    "         objective='binary:logistic',\n",
    "         eval_metric='auc',\n",
    "         use_label_encoder=False,\n",
    "         n_estimators=200,\n",
    "         max_depth=5,\n",
    "         learning_rate=0.05,\n",
    "         random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [100, 200],\n",
    "    'clf__max_depth': [3, 5, 7],\n",
    "    'clf__learning_rate': [0.01, 0.05]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=TimeSeriesSplit(n_splits=5), scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"XGBoost Best params:\", grid.best_params_)\n",
    "best_model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4326fd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.1: Prediction & Classification Report\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"\\nClassification Report on Test Set:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 9.2: ROC AUC + Precision‐Recall AUC\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "print(f\"Test ROC AUC:  {roc_auc:.4f}\")\n",
    "print(f\"Test PR AUC:   {pr_auc:.4f}\")\n",
    "\n",
    "# 9.3: Display a confusion matrix if you like\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix (low values = better balance):\\n\", cm)\n",
    "\n",
    "# ───────────\n",
    "# 10. FEATURE IMPORTANCE AND NEXT STEPS\n",
    "# ───────────\n",
    "\n",
    "importances = best_model.named_steps['clf'].feature_importances_\n",
    "feat_imp = pd.Series(importances, index=feature_columns).sort_values(ascending=False)\n",
    "print(\"\\nTop 10 Feature Importances:\")\n",
    "print(feat_imp.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
