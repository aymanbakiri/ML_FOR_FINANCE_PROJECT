{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "566b24f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3438676f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from data_preprocessing.merge import df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8899cf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [\n",
    "    # Price/technical:\n",
    "    'momentum_3m', 'momentum_6m', 'momentum_12m', 'volatility_12m',\n",
    "\n",
    "    # Basic YTD fundamentals (optional—tree can split on scale):\n",
    "    'revty', 'saley', 'capxy', 'oibdpy', 'rdipay', 'xsgay', 'txpdy', 'epsfxy', 'cshfdy', 'xoptepsy',\n",
    "\n",
    "    # Engineered ratios:\n",
    "    'EBIT_margin', 'R&D_intensity', 'SGA_intensity', 'Tax_rate', 'Capex_to_Revenue',\n",
    "\n",
    "    # QoQ growth rates:\n",
    "    'revty_QoQ_growth', 'oibdpy_QoQ_growth', 'rdipay_QoQ_growth', 'xsgay_QoQ_growth'\n",
    "]\n",
    "\n",
    "df = df.dropna(subset=feature_columns + ['y']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9980d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[feature_columns]\n",
    "y = df['y']\n",
    "\n",
    "# Instead of a fixed 80/20 cutoff, build an expanding‐window cross‐validation\n",
    "# but keep a final out‐of‐sample test set (last 20% of months).\n",
    "n_obs = len(df)\n",
    "cutpoint = int(n_obs * 0.8)\n",
    "\n",
    "X_train = X.iloc[:cutpoint]\n",
    "y_train = y.iloc[:cutpoint]\n",
    "\n",
    "X_test  = X.iloc[cutpoint:]\n",
    "y_test  = y.iloc[cutpoint:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3acc1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best parameters: {'clf__max_depth': 7, 'clf__max_features': 'sqrt', 'clf__n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "from models.rf_classifier import build_rf_pipeline\n",
    "\n",
    "pipe, param_grid = build_rf_pipeline()\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    cv=tscv,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "best_model = grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bcb69cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.42      0.41       344\n",
      "           1       0.62      0.61      0.61       531\n",
      "\n",
      "    accuracy                           0.53       875\n",
      "   macro avg       0.51      0.51      0.51       875\n",
      "weighted avg       0.54      0.53      0.54       875\n",
      "\n",
      "Test ROC AUC:  0.5098\n",
      "Test PR AUC:   0.6283\n",
      "Confusion Matrix (low values = better balance):\n",
      " [[143 201]\n",
      " [206 325]]\n",
      "\n",
      "Top 10 Feature Importances:\n",
      "momentum_12m         0.080030\n",
      "Capex_to_Revenue     0.057543\n",
      "volatility_12m       0.054945\n",
      "momentum_6m          0.053983\n",
      "momentum_3m          0.052132\n",
      "oibdpy_QoQ_growth    0.050244\n",
      "Tax_rate             0.047652\n",
      "xsgay_QoQ_growth     0.046024\n",
      "revty_QoQ_growth     0.044452\n",
      "cshfdy               0.043844\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from utils import report\n",
    "\n",
    "report(y_test, X_test, best_model, feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "654d833c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [16:38:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1748292887431/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "from models.xgb_classifier import build_xgb_pipeline\n",
    "\n",
    "pipe, param_grid = build_xgb_pipeline()\n",
    "\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=TimeSeriesSplit(n_splits=5), scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "grid.fit(X_train, y_train)\n",
    "best_model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4326fd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.20      0.27       344\n",
      "           1       0.61      0.82      0.70       531\n",
      "\n",
      "    accuracy                           0.57       875\n",
      "   macro avg       0.51      0.51      0.48       875\n",
      "weighted avg       0.53      0.57      0.53       875\n",
      "\n",
      "Test ROC AUC:  0.5141\n",
      "Test PR AUC:   0.6358\n",
      "Confusion Matrix (low values = better balance):\n",
      " [[ 68 276]\n",
      " [ 96 435]]\n",
      "\n",
      "Top 10 Feature Importances:\n",
      "oibdpy_QoQ_growth    0.074323\n",
      "xsgay_QoQ_growth     0.059595\n",
      "momentum_12m         0.054282\n",
      "momentum_3m          0.052295\n",
      "Tax_rate             0.050510\n",
      "Capex_to_Revenue     0.049910\n",
      "EBIT_margin          0.048552\n",
      "oibdpy               0.048518\n",
      "cshfdy               0.048081\n",
      "xoptepsy             0.047111\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "report(y_test, X_test, best_model, feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe0c207",
   "metadata": {},
   "source": [
    "## DEEP LEARNING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4a37a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from models.nn_models import EnhancedLSTM, LargeLSTM, SmallLSTM, StockTransformer, InceptionTime, train\n",
    "from utils import eval_model\n",
    "\n",
    "# Device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3026d30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import build_sequences, split_data, make_dataloaders, make_loss\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "df_scaled = df.copy()\n",
    "df_scaled[feature_columns] = scaler.fit_transform(df[feature_columns])\n",
    "\n",
    "# Group key\n",
    "group_key = 'PERMNO' if 'PERMNO' in df_scaled.columns else 'CUSIP'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e25669c",
   "metadata": {},
   "source": [
    "### \"EnhancedLSTM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d283a9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build sequences with 24-month window\n",
    "WINDOW     = 24\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "X, y = build_sequences(\n",
    "    df            = df_scaled,\n",
    "    feature_columns = feature_columns,\n",
    "    label_column  = 'y',\n",
    "    group_key     = group_key,\n",
    "    window        = WINDOW\n",
    ")\n",
    "\n",
    "# Split\n",
    "splits = split_data(X, y, train_frac=0.8, val_frac=0.2)\n",
    "\n",
    "# DataLoaders\n",
    "dl_train, dl_val, dl_test = make_dataloaders(splits, BATCH_SIZE)\n",
    "\n",
    "# Loss\n",
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = splits\n",
    "criterion = make_loss(splits[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f3d38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Loss 0.6839 | Val AUC 0.4226\n",
      "Epoch 02 | Loss 0.6642 | Val AUC 0.4065\n",
      "Epoch 03 | Loss 0.6548 | Val AUC 0.4071\n",
      "Epoch 04 | Loss 0.6459 | Val AUC 0.4131\n",
      "Epoch 05 | Loss 0.6326 | Val AUC 0.4214\n",
      "Epoch 06 | Loss 0.6315 | Val AUC 0.4208\n",
      "Epoch 07 | Loss 0.6214 | Val AUC 0.4202\n",
      "Epoch 08 | Loss 0.6313 | Val AUC 0.4238\n",
      "Epoch 09 | Loss 0.6321 | Val AUC 0.4220\n",
      "Epoch 10 | Loss 0.6258 | Val AUC 0.4250\n",
      "Epoch 11 | Loss 0.6130 | Val AUC 0.4268\n",
      "Epoch 12 | Loss 0.6126 | Val AUC 0.4286\n",
      "Epoch 13 | Loss 0.6111 | Val AUC 0.4292\n",
      "Epoch 14 | Loss 0.6230 | Val AUC 0.4310\n",
      "Epoch 15 | Loss 0.6214 | Val AUC 0.4298\n",
      "Epoch 16 | Loss 0.6225 | Val AUC 0.4310\n",
      "Epoch 17 | Loss 0.6152 | Val AUC 0.4286\n",
      "Epoch 18 | Loss 0.6114 | Val AUC 0.4286\n",
      "Epoch 19 | Loss 0.6050 | Val AUC 0.4268\n",
      "Epoch 20 | Loss 0.6235 | Val AUC 0.4268\n",
      "Epoch 21 | Loss 0.6089 | Val AUC 0.4268\n",
      "Epoch 22 | Loss 0.6029 | Val AUC 0.4268\n",
      "Epoch 23 | Loss 0.6147 | Val AUC 0.4268\n",
      "Epoch 24 | Loss 0.6182 | Val AUC 0.4256\n",
      "Epoch 25 | Loss 0.6091 | Val AUC 0.4256\n",
      "Epoch 26 | Loss 0.6170 | Val AUC 0.4256\n",
      "Early stopping.\n",
      "\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.3261    0.4545    0.3797        33\n",
      "         1.0     0.6842    0.5571    0.6142        70\n",
      "\n",
      "    accuracy                         0.5243       103\n",
      "   macro avg     0.5051    0.5058    0.4970       103\n",
      "weighted avg     0.5695    0.5243    0.5391       103\n",
      "\n",
      "Confusion Matrix:\n",
      "[[15 18]\n",
      " [31 39]]\n",
      "\n",
      "Test ROC AUC:  0.4931\n",
      "Test PR AUC:   0.7093\n",
      "Test Accuracy: 0.5243\n"
     ]
    }
   ],
   "source": [
    "model = EnhancedLSTM(in_dim=len(feature_columns)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3)\n",
    "\n",
    "# Training \n",
    "train(model, dl_train, dl_val, optimizer, scheduler, criterion, device, patience=10)\n",
    "\n",
    "eval_model(model, dl_test, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ed1368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW = 6\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "X, y = build_sequences(\n",
    "    df            = df_scaled,\n",
    "    feature_columns = feature_columns,\n",
    "    label_column  = 'y',\n",
    "    group_key     = group_key,\n",
    "    window        = WINDOW\n",
    ")\n",
    "\n",
    "# Split\n",
    "splits = split_data(X, y, train_frac=0.8, val_frac=0.2)\n",
    "\n",
    "# DataLoaders\n",
    "dl_train, dl_val, dl_test = make_dataloaders(splits, BATCH_SIZE)\n",
    "\n",
    "# Loss\n",
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = splits\n",
    "criterion = make_loss(splits[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5614223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 0.6145 | Val AUC: 0.4997\n",
      "Epoch 02 | Train Loss: 0.5955 | Val AUC: 0.5188\n",
      "Epoch 03 | Train Loss: 0.5921 | Val AUC: 0.4975\n",
      "Epoch 04 | Train Loss: 0.5931 | Val AUC: 0.4527\n",
      "Epoch 05 | Train Loss: 0.5907 | Val AUC: 0.5050\n",
      "Epoch 06 | Train Loss: 0.5876 | Val AUC: 0.5045\n",
      "Epoch 07 | Train Loss: 0.5842 | Val AUC: 0.4982\n",
      "Epoch 08 | Train Loss: 0.5822 | Val AUC: 0.5015\n",
      "Epoch 09 | Train Loss: 0.5798 | Val AUC: 0.4970\n",
      "Epoch 10 | Train Loss: 0.5784 | Val AUC: 0.4949\n",
      "Epoch 11 | Train Loss: 0.5753 | Val AUC: 0.4967\n",
      "Epoch 12 | Train Loss: 0.5792 | Val AUC: 0.4971\n",
      "Early stopping at epoch 12\n",
      "\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.4483    0.9952    0.6181       209\n",
      "         1.0     0.7500    0.0116    0.0228       259\n",
      "\n",
      "    accuracy                         0.4509       468\n",
      "   macro avg     0.5991    0.5034    0.3205       468\n",
      "weighted avg     0.6153    0.4509    0.2887       468\n",
      "\n",
      "Confusion Matrix (low values = better balance):\n",
      "[[208   1]\n",
      " [256   3]]\n",
      "\n",
      "Test ROC AUC:  0.4965\n",
      "Test PR AUC:   0.5652\n",
      "Test Accuracy: 0.4509\n"
     ]
    }
   ],
   "source": [
    "from models.nn_models import SmallLSTM\n",
    "\n",
    "\n",
    "model = SmallLSTM(len(feature_columns)).to(device)\n",
    "\n",
    "pos_w = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "criterion = nn.BCEWithLogitsLoss(\n",
    "    pos_weight=torch.tensor(pos_w, device=device, dtype=torch.float32)\n",
    ")\n",
    "\n",
    "model = EnhancedLSTM(in_dim=len(feature_columns)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3)\n",
    "\n",
    "\n",
    "train(model, dl_train, dl_val, optimizer, scheduler, criterion, device, patience=10)\n",
    "\n",
    "eval_model(model, dl_test, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18ab20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 0.5921 | Val AUC: 0.5333\n",
      "Epoch 02 | Train Loss: 0.5862 | Val AUC: 0.5131\n",
      "Epoch 03 | Train Loss: 0.5786 | Val AUC: 0.5611\n",
      "Epoch 04 | Train Loss: 0.5694 | Val AUC: 0.5676\n",
      "Epoch 05 | Train Loss: 0.5599 | Val AUC: 0.6160\n",
      "Epoch 06 | Train Loss: 0.5518 | Val AUC: 0.5645\n",
      "Epoch 07 | Train Loss: 0.5297 | Val AUC: 0.6170\n",
      "Epoch 08 | Train Loss: 0.5077 | Val AUC: 0.5730\n",
      "Epoch 09 | Train Loss: 0.4834 | Val AUC: 0.5968\n",
      "Epoch 10 | Train Loss: 0.4509 | Val AUC: 0.5877\n",
      "Epoch 11 | Train Loss: 0.4129 | Val AUC: 0.5959\n",
      "Epoch 12 | Train Loss: 0.3653 | Val AUC: 0.5782\n",
      "Epoch 13 | Train Loss: 0.3355 | Val AUC: 0.5860\n",
      "Epoch 14 | Train Loss: 0.2971 | Val AUC: 0.5452\n",
      "Epoch 15 | Train Loss: 0.2622 | Val AUC: 0.5521\n",
      "\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.5200    0.4976    0.5086       209\n",
      "         1.0     0.6082    0.6293    0.6186       259\n",
      "\n",
      "    accuracy                         0.5705       468\n",
      "   macro avg     0.5641    0.5635    0.5636       468\n",
      "weighted avg     0.5688    0.5705    0.5695       468\n",
      "\n",
      "Confusion Matrix (low values = better balance):\n",
      "[[104 105]\n",
      " [ 96 163]]\n",
      "\n",
      "Test ROC AUC:  0.5807\n",
      "Test PR AUC:   0.6213\n",
      "Test Accuracy: 0.5705\n"
     ]
    }
   ],
   "source": [
    "from models.nn_models import LargeLSTM\n",
    "\n",
    "\n",
    "model = LargeLSTM(len(feature_columns)).to(device)\n",
    "\n",
    "pos_w = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "criterion = nn.BCEWithLogitsLoss(\n",
    "    pos_weight=torch.tensor(pos_w, device=device, dtype=torch.float32)\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "train(model, dl_train, dl_val, optimizer, scheduler, criterion, device, patience=10)\n",
    "\n",
    "eval_model(model, dl_test, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bcbdcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 0.5960 | Val AUC: 0.5742\n",
      "Epoch 02 | Train Loss: 0.5952 | Val AUC: 0.5517\n",
      "Epoch 03 | Train Loss: 0.5922 | Val AUC: 0.5405\n",
      "Epoch 04 | Train Loss: 0.5898 | Val AUC: 0.5289\n",
      "Epoch 05 | Train Loss: 0.5879 | Val AUC: 0.5586\n",
      "Epoch 06 | Train Loss: 0.5839 | Val AUC: 0.5559\n",
      "Early stopping at epoch 6\n",
      "\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.5257    0.4402    0.4792       209\n",
      "         1.0     0.6007    0.6795    0.6377       259\n",
      "\n",
      "    accuracy                         0.5726       468\n",
      "   macro avg     0.5632    0.5599    0.5584       468\n",
      "weighted avg     0.5672    0.5726    0.5669       468\n",
      "\n",
      "Confusion Matrix (low values = better balance):\n",
      "[[ 92 117]\n",
      " [ 83 176]]\n",
      "\n",
      "Test ROC AUC:  0.6066\n",
      "Test PR AUC:   0.6635\n",
      "Test Accuracy: 0.5726\n"
     ]
    }
   ],
   "source": [
    "from models.nn_models import StockTransformer\n",
    "\n",
    "\n",
    "model = StockTransformer(len(feature_columns), window=WINDOW).to(device)\n",
    "\n",
    "# Loss & optimizer (with class weighting)\n",
    "pos_w = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "criterion = nn.BCEWithLogitsLoss(\n",
    "    pos_weight=torch.tensor(pos_w, device=device, dtype=torch.float32)\n",
    ")\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, factor=0.5)\n",
    "\n",
    "\n",
    "train(model, dl_train, dl_val, optimizer, scheduler, criterion, device, patience=10)\n",
    "\n",
    "eval_model(model, dl_test, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c789524e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 0.6048 | Val AUC: 0.5436\n",
      "Epoch 02 | Train Loss: 0.5881 | Val AUC: 0.5549\n",
      "Epoch 03 | Train Loss: 0.5838 | Val AUC: 0.5428\n",
      "Epoch 04 | Train Loss: 0.5742 | Val AUC: 0.5495\n",
      "Epoch 05 | Train Loss: 0.5639 | Val AUC: 0.5139\n",
      "Epoch 06 | Train Loss: 0.5574 | Val AUC: 0.5351\n",
      "Epoch 07 | Train Loss: 0.5401 | Val AUC: 0.5579\n",
      "Epoch 08 | Train Loss: 0.5344 | Val AUC: 0.5609\n",
      "Epoch 09 | Train Loss: 0.5138 | Val AUC: 0.5491\n",
      "Epoch 10 | Train Loss: 0.5203 | Val AUC: 0.5471\n",
      "Epoch 11 | Train Loss: 0.5092 | Val AUC: 0.5371\n",
      "Epoch 12 | Train Loss: 0.5030 | Val AUC: 0.5414\n",
      "Epoch 13 | Train Loss: 0.4758 | Val AUC: 0.5353\n",
      "Early stopping at epoch 13\n",
      "\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.5568    0.4689    0.5091       209\n",
      "         1.0     0.6199    0.6988    0.6570       259\n",
      "\n",
      "    accuracy                         0.5962       468\n",
      "   macro avg     0.5883    0.5839    0.5830       468\n",
      "weighted avg     0.5917    0.5962    0.5909       468\n",
      "\n",
      "Confusion Matrix (low values = better balance):\n",
      "[[ 98 111]\n",
      " [ 78 181]]\n",
      "\n",
      "Test ROC AUC:  0.6346\n",
      "Test PR AUC:   0.6853\n",
      "Test Accuracy: 0.5962\n"
     ]
    }
   ],
   "source": [
    "from models.nn_models import InceptionModule, InceptionTime\n",
    "\n",
    "model = InceptionTime(\n",
    "    in_dim=len(feature_columns),\n",
    "    num_blocks=3,\n",
    "    out_channels=32,\n",
    "    kernel_sizes=[3,5,7],\n",
    "    bottleneck_channels=32,\n",
    "    use_residual=True,\n",
    "    dropout=0.2\n",
    ").to(device)\n",
    "\n",
    "\n",
    "pos_w = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "criterion = nn.BCEWithLogitsLoss(\n",
    "    pos_weight=torch.tensor(pos_w, device=device, dtype=torch.float32)\n",
    ")\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, factor=0.5)\n",
    "\n",
    "\n",
    "train(model, dl_train, dl_val, optimizer, scheduler, criterion, device, patience=10)\n",
    "\n",
    "eval_model(model, dl_test, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
