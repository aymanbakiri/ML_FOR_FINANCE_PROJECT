{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25a74c32",
   "metadata": {},
   "source": [
    "# Monthly CRSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d836f0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41bc204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Monthly CRSP\n",
    "\n",
    "CRSP_PATH = 'data/monthly_crsp.csv'\n",
    "df_crsp = pd.read_csv(\n",
    "    CRSP_PATH ,\n",
    "    parse_dates=['MthCalDt'],\n",
    "    usecols=['PERMNO','CUSIP','MthCalDt','MthRet']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e0f3bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only good returns\n",
    "df_crsp = df_crsp.dropna(subset=['MthRet'])\n",
    "df_crsp['MthRet'] = df_crsp['MthRet'].astype(float)\n",
    "\n",
    "# Sort so shift is correct\n",
    "df_crsp = df_crsp.sort_values(['CUSIP','MthCalDt'])\n",
    "\n",
    "# # Create next‐month return target and binary label\n",
    "# df_crsp['Ret_t1'] = df_crsp.groupby('CUSIP')['MthRet'].shift(-1)\n",
    "# df_crsp['y'] = (df_crsp['Ret_t1'] > 0).astype(int)\n",
    "# df_crsp = df_crsp.dropna(subset=['y'])  # drop last obs per series\n",
    "\n",
    "# Create next‐month return target and binary label\n",
    "df_crsp['y'] = df_crsp.groupby('CUSIP')['MthRet'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01aa4c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinna\\AppData\\Local\\Temp\\ipykernel_4468\\1655684760.py:5: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_comp = pd.read_csv(\n",
      "C:\\Users\\sinna\\AppData\\Local\\Temp\\ipykernel_4468\\1655684760.py:5: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df_comp = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          gvkey   datadate  fyearq  fqtr  fyr indfmt consol popsrc datafmt  \\\n",
      "0          1000 1966-03-31    1966   1.0   12   INDL      C      D     STD   \n",
      "1          1000 1966-06-30    1966   2.0   12   INDL      C      D     STD   \n",
      "2          1000 1966-09-30    1966   3.0   12   INDL      C      D     STD   \n",
      "3          1000 1966-12-31    1966   4.0   12   INDL      C      D     STD   \n",
      "4          1000 1967-03-31    1967   1.0   12   INDL      C      D     STD   \n",
      "...         ...        ...     ...   ...  ...    ...    ...    ...     ...   \n",
      "2052009  356687 2023-09-30    2023   3.0   12   INDL      C      D     STD   \n",
      "2052010  356687 2023-12-31    2023   4.0   12   INDL      C      D     STD   \n",
      "2052011  356687 2024-03-31    2024   1.0   12   INDL      C      D     STD   \n",
      "2052012  356687 2024-06-30    2024   2.0   12   INDL      C      D     STD   \n",
      "2052013  356687 2024-09-30    2024   3.0   12   INDL      C      D     STD   \n",
      "\n",
      "           tic  ... xoptepsqpy xoptepsy xoptqpy xopty xrdy   xsgay  exchg  \\\n",
      "0         AE.2  ...        NaN      NaN     NaN   NaN  NaN     NaN   12.0   \n",
      "1         AE.2  ...        NaN      NaN     NaN   NaN  NaN     NaN   12.0   \n",
      "2         AE.2  ...        NaN      NaN     NaN   NaN  NaN     NaN   12.0   \n",
      "3         AE.2  ...        NaN      NaN     NaN   NaN  NaN     NaN   12.0   \n",
      "4         AE.2  ...        NaN      NaN     NaN   NaN  NaN     NaN   12.0   \n",
      "...        ...  ...        ...      ...     ...   ...  ...     ...    ...   \n",
      "2052009  SASKF  ...        NaN      NaN     NaN   NaN  NaN   8.866   19.0   \n",
      "2052010  SASKF  ...        NaN      NaN     NaN   NaN  NaN  15.103   19.0   \n",
      "2052011  SASKF  ...        NaN      NaN     NaN   NaN  NaN   4.302   19.0   \n",
      "2052012  SASKF  ...        NaN      NaN     NaN   NaN  NaN   8.307   19.0   \n",
      "2052013  SASKF  ...        NaN      NaN     NaN   NaN  NaN  10.214   19.0   \n",
      "\n",
      "         cik  costat  fic  \n",
      "0        NaN       I  USA  \n",
      "1        NaN       I  USA  \n",
      "2        NaN       I  USA  \n",
      "3        NaN       I  USA  \n",
      "4        NaN       I  USA  \n",
      "...      ...     ...  ...  \n",
      "2052009  NaN       A  CAN  \n",
      "2052010  NaN       A  CAN  \n",
      "2052011  NaN       A  CAN  \n",
      "2052012  NaN       A  CAN  \n",
      "2052013  NaN       A  CAN  \n",
      "\n",
      "[2052014 rows x 256 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load Compustat Fundamentals\n",
    "\n",
    "COMP_PATH = 'data/CompFirmCharac.csv'\n",
    "\n",
    "df_comp = pd.read_csv(\n",
    "    COMP_PATH,\n",
    "    parse_dates=['datadate'], dayfirst=True,\n",
    ")\n",
    "\n",
    "print(df_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68d2000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim CUSIP to 8 chars and filter to industrial/consolidated\n",
    "df_comp['cusip'] = df_comp['cusip'].astype(str).str[:8]\n",
    "df_comp = df_comp[\n",
    "    (df_comp['indfmt'] == 'INDL') &\n",
    "    (df_comp['consol'] == 'C')\n",
    "]\n",
    "\n",
    "# Pick three example fundamentals\n",
    "fund_cols = ['revty', 'saley', 'capxy']  ########################## why choose only 3 columns?\n",
    "\n",
    "# fund_cols = df_comp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a3cb521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "missing = [c for c in fund_cols if c not in df_comp.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"These Compustat codes are missing: {missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03abf47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp = df_comp[['cusip','datadate'] + fund_cols].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c0fc76",
   "metadata": {},
   "source": [
    "### MERGE FEATURES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "43dba560",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crsp['date'] = df_crsp['MthCalDt']\n",
    "df_crsp['cusip'] = df_crsp['CUSIP']\n",
    "\n",
    "df_crsp = df_crsp.dropna(subset=['cusip', 'date'])\n",
    "df_crsp['cusip'] = df_crsp['cusip'].astype(str).str[:8]\n",
    "df_crsp['date']  = pd.to_datetime(df_crsp['date'])\n",
    "df_crsp = df_crsp.set_index('date').sort_index()\n",
    "\n",
    "\n",
    "\n",
    "# df_comp = df_comp.dropna(subset=['cusip', 'datadate'])\n",
    "df_comp['cusip'] = df_comp['cusip'].astype(str).str[:8]\n",
    "# df_comp['datadate'] = pd.to_datetime(df_comp['datadate'])\n",
    "\n",
    "# # Rename and set index\n",
    "# df_comp = df_comp.rename(columns={'datadate':'date'})\n",
    "# df_comp = df_comp.set_index('date').sort_index()\n",
    "\n",
    "\n",
    "df_merged = pd.merge_asof(\n",
    "    left=df_crsp,\n",
    "    right=df_comp[['cusip'] + fund_cols],\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    by='cusip',\n",
    "    direction='backward',\n",
    "    allow_exact_matches=True\n",
    ").reset_index()  # brings 'date' back as a column\n",
    "\n",
    "df_merged = df_merged.dropna(subset=fund_cols + ['y'])\n",
    "\n",
    "\n",
    "\n",
    "df_merged = df_merged.drop('MthCalDt', axis=1)\n",
    "df_merged = df_merged.drop('cusip', axis=1)\n",
    "# df_merged = df_merged.drop('column_name', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_merged['month'] = df_merged['date'].dt.month\n",
    "\n",
    "# One-hot encode the month column\n",
    "month_dummies = pd.get_dummies(df_merged['month'], prefix='month')\n",
    "df_merged = pd.concat([df_merged, month_dummies], axis=1)\n",
    "\n",
    "# Drop the original month column\n",
    "df_merged.drop(columns=['month'], inplace=True)\n",
    "\n",
    "\n",
    "cols = [col for col in df_merged.columns if col != 'y'] + ['y']\n",
    "df_merged = df_merged[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "13bd5bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head()\n",
    "\n",
    "# from pathlib import Path\n",
    "\n",
    "# # Set current directory\n",
    "# current_dir = Path(__file__).parent\n",
    "\n",
    "# df_merged.to_csv(current_dir / 'output_data.csv', index=False)\n",
    "\n",
    "df_merged.to_csv('output_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168d1f72",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa94a000",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = fund_cols\n",
    "X = df_merged[features]\n",
    "y = df_merged['y']\n",
    "\n",
    "# Chronological 80/20 split\n",
    "cut = int(len(df_merged)*0.8)\n",
    "X_train, X_test = X.iloc[:cut], X.iloc[cut:]\n",
    "y_train, y_test = y.iloc[:cut], y.iloc[cut:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "184039ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 12\u001b[0m\n\u001b[0;32m      1\u001b[0m pipe \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[0;32m      2\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimpute\u001b[39m\u001b[38;5;124m'\u001b[39m, SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[0;32m      3\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;124m'\u001b[39m,  StandardScaler()),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     ))\n\u001b[0;32m     10\u001b[0m ])\n\u001b[1;32m---> 12\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m pipe\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification Report on Test Set:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\pipeline.py:473\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    472\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 473\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_forest.py:421\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    414\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    415\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSum of y is not strictly positive which \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    416\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis necessary for Poisson regression.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m         )\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_samples, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m--> 421\u001b[0m y, expanded_class_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_y_class_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(y, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m!=\u001b[39m DOUBLE \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m y\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mcontiguous:\n\u001b[0;32m    424\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mascontiguousarray(y, dtype\u001b[38;5;241m=\u001b[39mDOUBLE)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_forest.py:831\u001b[0m, in \u001b[0;36mForestClassifier._validate_y_class_weight\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_y_class_weight\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[1;32m--> 831\u001b[0m     \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(y)\n\u001b[0;32m    834\u001b[0m     expanded_class_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\multiclass.py:219\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    211\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    218\u001b[0m ]:\n\u001b[1;32m--> 219\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Maybe you are trying to fit a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier, which expects discrete classes on a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression target with continuous values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    223\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='median')),\n",
    "    ('scale',  StandardScaler()),\n",
    "    ('clf',    RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(\"Classification Report on Test Set:\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
