{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3438676f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    precision_recall_curve,\n",
    "    auc,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96df90f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinna\\AppData\\Local\\Temp\\ipykernel_21600\\616781079.py:15: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_comp = pd.read_csv(\n",
      "C:\\Users\\sinna\\AppData\\Local\\Temp\\ipykernel_21600\\616781079.py:15: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df_comp = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "# Load Monthly CRSP\n",
    "\n",
    "CRSP_PATH = '../data/monthly_crsp.csv'\n",
    "df_crsp = pd.read_csv(\n",
    "    CRSP_PATH ,\n",
    "    parse_dates=['MthCalDt'],\n",
    "    usecols=['PERMNO','CUSIP','MthCalDt','MthRet']\n",
    ")\n",
    "\n",
    "\n",
    "# Load Compustat Fundamentals\n",
    "\n",
    "COMP_PATH = '../data/CompFirmCharac.csv'\n",
    "\n",
    "df_comp = pd.read_csv(\n",
    "    COMP_PATH,\n",
    "    parse_dates=['datadate'], dayfirst=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c01ee4",
   "metadata": {},
   "source": [
    "### CLEAN CRSP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71ecff37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1: Keep only rows where MthRet is available and cast to float\n",
    "df_crsp = df_crsp.dropna(subset=['MthRet']).copy()\n",
    "df_crsp['MthRet'] = df_crsp['MthRet'].astype(float)\n",
    "\n",
    "# 2.2: Sort by CUSIP, date so that shift is correct\n",
    "df_crsp['date'] = pd.to_datetime(df_crsp['MthCalDt'].astype(str), format='mixed')\n",
    "df_crsp = df_crsp.sort_values(['CUSIP','date']).reset_index(drop=True)\n",
    "\n",
    "# 2.3: Create next‐month return target (binary)\n",
    "df_crsp['Ret_t1'] = df_crsp.groupby('CUSIP')['MthRet'].shift(-1)\n",
    "# df_crsp['y'] = df_crsp.groupby('CUSIP')['MthRet'].shift(-1)\n",
    "df_crsp['y'] = (df_crsp['Ret_t1'] > 0).astype(int)\n",
    "df_crsp = df_crsp.dropna(subset=['y']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3b6b77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            CUSIP   MthCalDt    MthRet       date    Ret_t1       EMA  \\\n",
      "2970518  68391610 1987-03-31 -0.384615 1987-03-31 -0.062500 -4.416586   \n",
      "2970519  68391610 1987-04-30 -0.062500 1987-04-30 -0.066667 -4.140666   \n",
      "1746075  39040610 1987-03-31  0.037486 1987-03-31 -0.039216  0.028843   \n",
      "1746076  39040610 1987-04-30 -0.039216 1987-04-30 -0.071429 -0.009357   \n",
      "1746077  39040610 1987-05-29 -0.071429 1987-05-29  0.052687 -0.075400   \n",
      "...           ...        ...       ...        ...       ...       ...   \n",
      "3917811  88160R10 2024-07-31  0.172781 2024-07-31 -0.077390  0.094132   \n",
      "3917812  88160R10 2024-08-30 -0.077390 2024-08-30  0.221942  0.015727   \n",
      "3917813  88160R10 2024-09-30  0.221942 2024-09-30 -0.045025  0.168567   \n",
      "3917814  88160R10 2024-10-31 -0.045025 2024-10-31  0.381469  0.112118   \n",
      "3917815  88160R10 2024-11-29  0.381469 2024-11-29  0.170008  0.309653   \n",
      "\n",
      "         Volatility        RSI      MACD  April  ...  February  January  July  \\\n",
      "2970518    6.008675  31.218276 -1.072760      0  ...         0        0     0   \n",
      "2970519    6.416235  22.507136 -1.026429      1  ...         0        0     0   \n",
      "1746075    0.058017  67.902789  0.006527      0  ...         0        0     0   \n",
      "1746076    0.057093  56.446075  0.001278      1  ...         0        0     0   \n",
      "1746077    0.065004  46.313294 -0.007746      0  ...         0        0     0   \n",
      "...             ...        ...       ...    ...  ...       ...      ...   ...   \n",
      "3917811    0.146526  54.063213 -0.009722      0  ...         0        0     1   \n",
      "3917812    0.148719  42.222613 -0.005101      0  ...         0        0     0   \n",
      "3917813    0.119113  49.167329  0.010568      0  ...         0        0     0   \n",
      "3917814    0.121613  48.826636  0.017277      0  ...         0        0     0   \n",
      "3917815    0.131800  60.834500  0.032353      0  ...         0        0     0   \n",
      "\n",
      "         June  March  May  November  October  September  y  \n",
      "2970518     0      1    0         0        0          0  0  \n",
      "2970519     0      0    0         0        0          0  0  \n",
      "1746075     0      1    0         0        0          0  0  \n",
      "1746076     0      0    0         0        0          0  0  \n",
      "1746077     0      0    1         0        0          0  1  \n",
      "...       ...    ...  ...       ...      ...        ... ..  \n",
      "3917811     0      0    0         0        0          0  0  \n",
      "3917812     0      0    0         0        0          0  1  \n",
      "3917813     0      0    0         0        0          1  0  \n",
      "3917814     0      0    0         0        1          0  1  \n",
      "3917815     0      0    0         1        0          0  1  \n",
      "\n",
      "[3997219 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "import calendar\n",
    "\n",
    "# Add technical indicators and months\n",
    "\n",
    "def compute_close(y_series):\n",
    "    close = (1 + y_series.fillna(0)).cumprod()\n",
    "    close.iloc[0] = 1.0\n",
    "    return close\n",
    "\n",
    "df_crsp = df_crsp.sort_values([\"PERMNO\", \"date\"])\n",
    "df_crsp[\"close\"] = df_crsp.groupby(\"PERMNO\")[\"MthRet\"].apply(compute_close).reset_index(level=0, drop=True)\n",
    "\n",
    "def calculate_rsi(series, window=14):\n",
    "    delta = series.diff()\n",
    "    up = delta.clip(lower=0)\n",
    "    down = -delta.clip(upper=0)\n",
    "    ma_up = up.rolling(window).mean()\n",
    "    ma_down = down.rolling(window).mean()\n",
    "    rs = ma_up / ma_down\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "# Group-wise calculations\n",
    "def add_technical_indicators(group):\n",
    "    group = group.copy()\n",
    "    group['EMA_Close'] = group['close'].ewm(span=14, adjust=False).mean()\n",
    "    group['EMA'] = (group['close'] - group['EMA_Close'])/ group['close']\n",
    "\n",
    "    rolling_std = group['close'].rolling(window=14).std()\n",
    "    group['Volatility'] = rolling_std / group['close']\n",
    "\n",
    "    group['RSI'] = calculate_rsi(group['close'])\n",
    "    \n",
    "    # MACD\n",
    "    ema12 = group['close'].ewm(span=12, adjust=False).mean()\n",
    "    ema26 = group['close'].ewm(span=26, adjust=False).mean()\n",
    "    group['MACD_diff'] = ema12 - ema26\n",
    "    group['MACD_Signal'] = group['MACD_diff'].ewm(span=9, adjust=False).mean()\n",
    "    group['MACD'] = (group['MACD_diff'] - group['MACD_Signal']) / group['close']\n",
    "\n",
    "\n",
    "    return group\n",
    "\n",
    "# Apply technical indicators to each stock (PERMNO)\n",
    "df_crsp = df_crsp.groupby(\"PERMNO\", group_keys=False).apply(add_technical_indicators, include_groups=False)\n",
    "\n",
    "df_crsp.drop(columns=[\"close\", \"EMA_Close\", \"MACD_diff\", \"MACD_Signal\", 'y_forward'], inplace=True, errors='ignore')\n",
    "\n",
    "# Add months\n",
    "df_crsp['month'] = df_crsp['date'].dt.month.map(lambda x: calendar.month_name[x])\n",
    "\n",
    "# Create dummy variables with month names as column names\n",
    "month_dummies = pd.get_dummies(df_crsp['month']).astype(int)\n",
    "\n",
    "# Concatenate dummies with original dataframe\n",
    "df_crsp = pd.concat([df_crsp, month_dummies], axis=1)\n",
    "\n",
    "# drop the intermediate 'month' column \n",
    "df_crsp = df_crsp.drop(columns=['month'])\n",
    "\n",
    "# Get the current columns\n",
    "cols = list(df_crsp.columns)\n",
    "\n",
    "# Move 'y' to the end if it exists\n",
    "if 'y' in cols:\n",
    "    cols.remove('y')\n",
    "    cols.append('y')\n",
    "\n",
    "# Reorder the DataFrame columns\n",
    "df_crsp = df_crsp[cols]\n",
    "\n",
    "df_crsp = df_crsp.dropna()\n",
    "print(df_crsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc8b4c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4: Generate price‐history features (momentum + volatility)\n",
    "#\n",
    "#   - 3M momentum: cumulative return over past 3 months (t-3 → t-1)\n",
    "#   - 6M momentum: cumulative return over past 6 months\n",
    "#   - 12M momentum: cumulative return over past 12 months\n",
    "#   - 12M rolling volatility: std of monthly returns over past 12 months\n",
    "#\n",
    "def compute_momentum_and_vol(df):\n",
    "    df = df.sort_values('date')\n",
    "    # Rolling log(1+return), because cumulative product of (1 + ret) = exp(sum(log(1+ret)))\n",
    "    df['log1p_ret'] = np.log1p(df['MthRet'])\n",
    "    df['log1p_ret_shift1'] = df.groupby('CUSIP')['log1p_ret'].shift(1)\n",
    "    df['cum12_1_log'] = df.groupby('CUSIP')['log1p_ret_shift1'].rolling(window=11).sum().reset_index(0,drop=True)\n",
    "    df['mom_12_1'] = np.expm1(df['cum12_1_log'])\n",
    "    df['cum3m_log'] = df.groupby('CUSIP')['log1p_ret'].rolling(window=3, min_periods=3).sum().reset_index(0,drop=True)\n",
    "    df['cum6m_log'] = df.groupby('CUSIP')['log1p_ret'].rolling(window=6, min_periods=6).sum().reset_index(0,drop=True)\n",
    "    df['cum12m_log'] = df.groupby('CUSIP')['log1p_ret'].rolling(window=12, min_periods=12).sum().reset_index(0,drop=True)\n",
    "    df['momentum_3m'] = np.expm1(df['cum3m_log'])    # exp(sum)-1 => (1+r1)*(1+r2)*(1+r3) - 1\n",
    "    df['momentum_6m'] = np.expm1(df['cum6m_log'])\n",
    "    df['momentum_12m'] = np.expm1(df['cum12m_log'])\n",
    "    df['volatility_12m'] = df.groupby('CUSIP')['MthRet'].rolling(window=12, min_periods=12).std().reset_index(0,drop=True)\n",
    "    # Drop intermediate log columns\n",
    "    return df.drop(columns=['log1p_ret','cum3m_log','cum6m_log','cum12m_log'])\n",
    "\n",
    "df_crsp = compute_momentum_and_vol(df_crsp)\n",
    "\n",
    "# 2.5: Trim CUSIP to 8 characters (for merging) and drop NA\n",
    "df_crsp['cusip'] = df_crsp['CUSIP'].astype(str).str[:8]\n",
    "df_crsp = df_crsp.dropna(subset=['cusip']).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a84c12",
   "metadata": {},
   "source": [
    "### CLEAN COMPFIRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3acc27fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1: Keep only Industrial & Consolidated\n",
    "df_comp = df_comp[\n",
    "    (df_comp['consol'] == 'C')\n",
    "].copy()\n",
    "\n",
    "# 3.2: Trim & parse keys/dates\n",
    "df_comp['cusip'] = df_comp['cusip'].astype(str).str[:8]\n",
    "df_comp['datadate'] = pd.to_datetime(df_comp['datadate'])\n",
    "df_comp = df_comp.dropna(subset=['cusip','datadate']).copy()\n",
    "\n",
    "# 3.3: Build “effective_date” = datadate + 45 calendar days,\n",
    "#      so that we only use Q data ~45 days after quarter‐end.\n",
    "df_comp['effective_date'] = df_comp['datadate'] + pd.Timedelta(days=45)\n",
    "df_comp = df_comp.set_index('effective_date').sort_index()\n",
    "\n",
    "# 3.4: Select a larger fundamental set (YTD flows + per‐share metrics)\n",
    "fundamental_cols = [\n",
    "    'revty',    # Revenue YTD\n",
    "    'saley',    # Sales YTD\n",
    "    'capxy',    # CapEx YTD\n",
    "    'oibdpy',   # EBITDA YTD\n",
    "    'rdipay',   # R&D expense YTD\n",
    "    'xsgay',    # SG&A expense YTD\n",
    "    'txpdy',    # Tax provision YTD\n",
    "    'epsfxy',   # Diluted EPS ex‐extra YTD\n",
    "    'cshfdy',   # Diluted shares YTD (millions)\n",
    "    'xoptepsy'  # Option expense per share YTD\n",
    "]\n",
    "\n",
    "df_comp_small = df_comp[['cusip'] + fundamental_cols].copy()\n",
    "\n",
    "# 3.5: For each “cusip + quarter,” drop exact duplicates\n",
    "df_comp_small = df_comp_small.reset_index().drop_duplicates(\n",
    "    subset=['cusip','effective_date']\n",
    ").set_index('effective_date').sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031bbf43",
   "metadata": {},
   "source": [
    "### MERGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3fc5166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1: Set df_crsp index to “date”\n",
    "df_crsp = df_crsp.set_index('date').sort_index()\n",
    "\n",
    "# 4.2: Merge (for every month, get the most recent Compustat row ≤ that month’s date)\n",
    "df_merged = pd.merge_asof(\n",
    "    left = df_crsp.reset_index(),\n",
    "    right = df_comp_small.reset_index(),\n",
    "    left_on = 'date',\n",
    "    right_on = 'effective_date',\n",
    "    by = 'cusip',\n",
    "    direction = 'backward',\n",
    "    allow_exact_matches=True\n",
    ").set_index('date')\n",
    "\n",
    "# 4.3: Drop rows where any of our fundamentals are NA, since we can’t compute ratios otherwise\n",
    "df_merged = df_merged.dropna(subset=fundamental_cols + ['y']).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "570dc693",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_merged.copy()\n",
    "\n",
    "# 5.1: Engineer simple ratios (safe‐guard divisions by zero)\n",
    "df['EBIT_margin']      = df['oibdpy'] / df['saley'].replace({0: np.nan})\n",
    "df['R&D_intensity']    = df['rdipay'] / df['saley'].replace({0: np.nan})\n",
    "df['SGA_intensity']    = df['xsgay'] / df['saley'].replace({0: np.nan})\n",
    "df['Tax_rate']         = df['txpdy']  / df['oibdpy'].replace({0: np.nan})\n",
    "df['Capex_to_Revenue'] = df['capxy']  / df['revty'].replace({0: np.nan})\n",
    "\n",
    "# 5.2: Compute QoQ growth rates on YTD fundamentals\n",
    "for col in ['revty','oibdpy','rdipay','xsgay']:\n",
    "    df[col + '_QoQ_growth'] = df.groupby('cusip')[col].pct_change()  # (This QY / Last QY) - 1\n",
    "\n",
    "# 5.3: Optionally drop some raw dollar‐amount YTD columns if you want just ratios\n",
    "#      (otherwise let the model pick scale vs. ratio)\n",
    "# df = df.drop(columns=['revty','saley','capxy','oibdpy','rdipay','xsgay','txpdy','epsfxy','cshfdy','xoptepsy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b27bfe5",
   "metadata": {},
   "source": [
    "### TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e77625e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [\n",
    "    # Price/technical:\n",
    "    'momentum_3m', 'momentum_6m', 'momentum_12m', 'volatility_12m',\n",
    "\n",
    "    # Basic YTD fundamentals (optional—tree can split on scale):\n",
    "    'revty', 'saley', 'capxy', 'oibdpy', 'rdipay', 'xsgay', 'txpdy', 'epsfxy', 'cshfdy', 'xoptepsy',\n",
    "\n",
    "    # Engineered ratios:\n",
    "    'EBIT_margin', 'R&D_intensity', 'SGA_intensity', 'Tax_rate', 'Capex_to_Revenue',\n",
    "\n",
    "    # QoQ growth rates:\n",
    "    'revty_QoQ_growth', 'oibdpy_QoQ_growth', 'rdipay_QoQ_growth', 'xsgay_QoQ_growth',\n",
    "\n",
    "    # Months\n",
    "    'January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December',\n",
    "\n",
    "    # Indicators\n",
    "    'EMA', 'Volatility', 'RSI', 'MACD'\n",
    "]\n",
    "\n",
    "# Drop any rows where engineered features are NaN\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df = df.dropna(subset=feature_columns + ['y']).copy()\n",
    "\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9980d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of a fixed 80/20 cutoff, build an expanding‐window cross‐validation\n",
    "# but keep a final out‐of‐sample test set (last 20% of months).\n",
    "n_obs = len(df)\n",
    "cutpoint = int(n_obs * 0.8)\n",
    "\n",
    "X_train = X.iloc[:cutpoint]\n",
    "y_train = y.iloc[:cutpoint]\n",
    "\n",
    "X_test  = X.iloc[cutpoint:]\n",
    "y_test  = y.iloc[cutpoint:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8eddb922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best parameters: {'clf__max_depth': 7, 'clf__max_features': 'log2', 'clf__n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# pipe = Pipeline([\n",
    "#     ('imputer', SimpleImputer(strategy='median')),\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('reg', RandomForestRegressor(random_state=42))\n",
    "# ])\n",
    "\n",
    "# param_grid = {\n",
    "#     'reg__n_estimators': [100, 200],\n",
    "#     'reg__max_depth': [5, 7, 9],\n",
    "#     'reg__max_features': ['sqrt', 'log2']\n",
    "# }\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler',   StandardScaler()),   # scale ratio features so splits are easier\n",
    "    ('clf',      RandomForestClassifier(random_state=42, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [100, 200],\n",
    "    'clf__max_depth': [5, 7, 9],\n",
    "    'clf__max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    cv=tscv,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "best_model = grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9bcb69cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.46      0.43       344\n",
      "           1       0.62      0.57      0.59       531\n",
      "\n",
      "    accuracy                           0.52       875\n",
      "   macro avg       0.51      0.51      0.51       875\n",
      "weighted avg       0.53      0.52      0.53       875\n",
      "\n",
      "Test ROC AUC:  0.5201\n",
      "Test PR AUC:   0.6402\n",
      "Confusion Matrix (low values = better balance):\n",
      " [[157 187]\n",
      " [229 302]]\n",
      "\n",
      "Top 10 Feature Importances:\n",
      "Capex_to_Revenue    0.047139\n",
      "Volatility          0.046972\n",
      "momentum_12m        0.046843\n",
      "momentum_3m         0.042584\n",
      "RSI                 0.042584\n",
      "MACD                0.041572\n",
      "volatility_12m      0.038254\n",
      "epsfxy              0.038173\n",
      "momentum_6m         0.038167\n",
      "SGA_intensity       0.036506\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 9.1: Prediction & Classification Report\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"\\nClassification Report on Test Set:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 9.2: ROC AUC + Precision‐Recall AUC\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "print(f\"Test ROC AUC:  {roc_auc:.4f}\")\n",
    "print(f\"Test PR AUC:   {pr_auc:.4f}\")\n",
    "\n",
    "# 9.3: Display a confusion matrix if you like\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix (low values = better balance):\\n\", cm)\n",
    "\n",
    "# ───────────\n",
    "# 10. FEATURE IMPORTANCE AND NEXT STEPS\n",
    "# ───────────\n",
    "\n",
    "importances = best_model.named_steps['clf'].feature_importances_\n",
    "feat_imp = pd.Series(importances, index=feature_columns).sort_values(ascending=False)\n",
    "print(\"\\nTop 10 Feature Importances:\")\n",
    "print(feat_imp.head(10))\n",
    "\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# y_pred = best_model.predict(X_test)\n",
    "\n",
    "# print(\"\\nRegression Metrics on Test Set:\")\n",
    "# print(f\"MAE:  {mean_absolute_error(y_test, y_pred):.4f}\")\n",
    "# print(f\"MSE:  {mean_squared_error(y_test, y_pred):.4f}\")\n",
    "# print(f\"R²:   {r2_score(y_test, y_pred):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a489edc",
   "metadata": {},
   "source": [
    "TRAINING 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "654d833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [\n",
    "    # Price/technical:\n",
    "    'momentum_3m', 'momentum_6m', 'mom_12_1', 'volatility_12m',\n",
    "\n",
    "    # Basic YTD fundamentals (optional—tree can split on scale):\n",
    "    'revty', 'saley', 'capxy', 'oibdpy', 'rdipay', 'xsgay', 'txpdy', 'epsfxy', 'cshfdy', 'xoptepsy',\n",
    "\n",
    "    # Engineered ratios:\n",
    "    'EBIT_margin', 'R&D_intensity', 'SGA_intensity', 'Tax_rate', 'Capex_to_Revenue',\n",
    "\n",
    "    # QoQ growth rates:\n",
    "    'revty_QoQ_growth', 'oibdpy_QoQ_growth', 'rdipay_QoQ_growth', 'xsgay_QoQ_growth',\n",
    "\n",
    "    # Months\n",
    "    'January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December',\n",
    "\n",
    "    # Indicators\n",
    "    'EMA', 'Volatility', 'RSI', 'MACD'\n",
    "]\n",
    "\n",
    "# Drop any rows where engineered features are NaN\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df = df.dropna(subset=feature_columns + ['y']).copy()\n",
    "\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8008f0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of a fixed 80/20 cutoff, build an expanding‐window cross‐validation\n",
    "# but keep a final out‐of‐sample test set (last 20% of months).\n",
    "n_obs = len(df)\n",
    "cutpoint = int(n_obs * 0.8)\n",
    "\n",
    "X_train = X.iloc[:cutpoint]\n",
    "y_train = y.iloc[:cutpoint]\n",
    "\n",
    "X_test  = X.iloc[cutpoint:]\n",
    "y_test  = y.iloc[cutpoint:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e02defc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "XGBoost Best params: {'clf__learning_rate': 0.01, 'clf__max_depth': 3, 'clf__n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinna\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler',   StandardScaler()),  \n",
    "    ('clf',      XGBClassifier(\n",
    "         objective='binary:logistic',\n",
    "         eval_metric='auc',\n",
    "         use_label_encoder=False,\n",
    "         n_estimators=200,\n",
    "         max_depth=5,\n",
    "         learning_rate=0.05,\n",
    "         random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [100, 200],\n",
    "    'clf__max_depth': [3, 5, 7],\n",
    "    'clf__learning_rate': [0.01, 0.05]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=TimeSeriesSplit(n_splits=5), scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"XGBoost Best params:\", grid.best_params_)\n",
    "best_model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4326fd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.19      0.27       344\n",
      "           1       0.61      0.83      0.71       531\n",
      "\n",
      "    accuracy                           0.58       875\n",
      "   macro avg       0.52      0.51      0.49       875\n",
      "weighted avg       0.54      0.58      0.53       875\n",
      "\n",
      "Test ROC AUC:  0.5138\n",
      "Test PR AUC:   0.6361\n",
      "Confusion Matrix (low values = better balance):\n",
      " [[ 66 278]\n",
      " [ 88 443]]\n",
      "\n",
      "Top 10 Feature Importances:\n",
      "xoptepsy             0.069767\n",
      "May                  0.067024\n",
      "October              0.051338\n",
      "April                0.049300\n",
      "June                 0.048363\n",
      "momentum_6m          0.047852\n",
      "MACD                 0.044416\n",
      "January              0.042819\n",
      "oibdpy_QoQ_growth    0.042389\n",
      "March                0.042241\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "# 9.1: Prediction & Classification Report\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"\\nClassification Report on Test Set:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 9.2: ROC AUC + Precision‐Recall AUC\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "print(f\"Test ROC AUC:  {roc_auc:.4f}\")\n",
    "print(f\"Test PR AUC:   {pr_auc:.4f}\")\n",
    "\n",
    "# 9.3: Display a confusion matrix if you like\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix (low values = better balance):\\n\", cm)\n",
    "\n",
    "# ───────────\n",
    "# 10. FEATURE IMPORTANCE AND NEXT STEPS\n",
    "# ───────────\n",
    "\n",
    "importances = best_model.named_steps['clf'].feature_importances_\n",
    "feat_imp = pd.Series(importances, index=feature_columns).sort_values(ascending=False)\n",
    "print(\"\\nTop 10 Feature Importances:\")\n",
    "print(feat_imp.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
